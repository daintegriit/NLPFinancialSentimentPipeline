{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a366236",
   "metadata": {},
   "source": [
    "Cell 1: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4dbdc2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn matplotlib optuna joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e7b0d",
   "metadata": {},
   "source": [
    "Cell 2: Load predictions and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920bc51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace paths with actual outputs\n",
    "xgb = pd.read_csv('/content/xgb_preds.csv')\n",
    "lstm = pd.read_csv('/content/lstm_preds.csv')\n",
    "catb = pd.read_csv('/content/catboost_preds.csv')\n",
    "bayes = pd.read_csv('/content/bayes_preds.csv')\n",
    "labels = pd.read_csv('/content/true_labels.csv')\n",
    "\n",
    "df = xgb.merge(lstm, on='date', suffixes=('_xgb', '_lstm'))\n",
    "df = df.merge(catb, on='date')\n",
    "df = df.rename(columns={'pred': 'pred_catboost'})\n",
    "df = df.merge(bayes, on='date')\n",
    "df = df.rename(columns={'pred': 'pred_bayes'})\n",
    "df = df.merge(labels, on='date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f4ab5",
   "metadata": {},
   "source": [
    "Cell 3: Score each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b0572",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model in ['xgb', 'lstm', 'catboost', 'bayes']:\n",
    "    y_pred = df[f'pred_{model}'].round()\n",
    "    acc = accuracy_score(df['true'], y_pred)\n",
    "    f1 = f1_score(df['true'], y_pred)\n",
    "    results[model] = {'Accuracy': acc, 'F1': f1}\n",
    "\n",
    "pd.DataFrame(results).T.sort_values(by='F1', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c25033",
   "metadata": {},
   "source": [
    "Cell 4: Auto-select best model (custom or Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea79c26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "best_model = max(results.items(), key=lambda x: x[1]['F1'])[0]\n",
    "print(f\"🏆 Best Model (by F1): {best_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fae1fb",
   "metadata": {},
   "source": [
    "Cell 5: Save model choice for app routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd71ccb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"best_model_selected.txt\", \"w\") as f:\n",
    "    f.write(best_model)\n",
    "\n",
    "print(\"✅ Best model name saved to best_model_selected.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed602b",
   "metadata": {},
   "source": [
    "BONUS: AutoML via Optuna (Optional Hyperparameter Search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554909e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    pred_xgb = df['pred_xgb'] * trial.suggest_float(\"xgb_weight\", 0, 1)\n",
    "    pred_lstm = df['pred_lstm'] * trial.suggest_float(\"lstm_weight\", 0, 1)\n",
    "    pred_cat = df['pred_catboost'] * trial.suggest_float(\"catboost_weight\", 0, 1)\n",
    "    \n",
    "    combined = (pred_xgb + pred_lstm + pred_cat) / 3\n",
    "    pred_label = (combined > 0.5).astype(int)\n",
    "    \n",
    "    return f1_score(df['true'], pred_label)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"🧠 Best F1:\", study.best_value)\n",
    "print(\"🎛️ Best weights:\", study.best_params)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
