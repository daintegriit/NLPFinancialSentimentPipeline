{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0814372f",
   "metadata": {},
   "source": [
    "üì¶ Cell 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ee9c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2f4bb3",
   "metadata": {},
   "source": [
    "üìö Cell 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c03e03",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd85c0",
   "metadata": {},
   "source": [
    "üìÅ Cell 3: Load Your Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d219fa5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load your LoRA fine-tuned Mistral-7B (or switch to LLaMA13B later)\n",
    "model_name = \"fin_llm_mistral_lora\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb28ad7",
   "metadata": {},
   "source": [
    "üß† Cell 4: Define LLM Response Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f25dfaa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt, max_tokens=512):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_tokens)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab839a7e",
   "metadata": {},
   "source": [
    "üí¨ Cell 5: Sample Prompt + Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b64dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "AAPL sentiment is rising rapidly and LSTM predicts a 0.9 probability of short-term upward movement. \n",
    "CatBoost also agrees with a 0.84 score. What should I do next?\n",
    "\"\"\"\n",
    "\n",
    "response = generate_response(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c3316",
   "metadata": {},
   "source": [
    "üîÅ Cell 6: Loop for Multiple Inputs (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d779a00",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_prompt = input(\"üß† Ask your financial LLM anything:\\n\")\n",
    "    if user_prompt.lower() in [\"exit\", \"quit\"]: break\n",
    "    print(\"üìà Response:\\n\", generate_response(user_prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b31ad1b",
   "metadata": {},
   "source": [
    "üìÇ Cell 7: Load Example Commands Dataset (Optional Agent Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f958ea3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Optional ‚Äî Load instruction dataset to fine-tune agent behavior further\n",
    "with open(\"../data/fin_llm_instruct.json\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Show a few examples\n",
    "for ex in dataset[:3]:\n",
    "    print(\"Instruction:\", ex[\"instruction\"])\n",
    "    print(\"Response:\", ex[\"response\"], \"\\n---\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
